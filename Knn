#ibm ml

#create features for classification
X = df[['column1', 'column2',...]].values  

# normalize those
X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))

#create label thats classified
y = df[''outcome'].values

#create test and train data set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)
print ('Train set:', X_train.shape,  y_train.shape)
print ('Test set:', X_test.shape,  y_test.shape)

#select value for k
k = 4

#Train Model   
model = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)

# prediction
yhat = model.predict(X_test)

# evaluate test accuracy on test set
print("Test set Accuracy: ", metrics.accuracy_score(y_test, yhat)

################### evaluate different values for k

Ks = 10
mean_acc = np.zeros((Ks-1))
std_acc = np.zeros((Ks-1))

for n in range(1,Ks):
    
    model = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)
    yhat=model.predict(X_test)
    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)

    
    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])

mean_acc

plt.plot(range(1,Ks),mean_acc,'g')
plt.show()
